{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0626dd35",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import GPT2Tokenizer, GPT2ForSequenceClassification, Trainer, TrainingArguments, GPT2Config\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from transformers import AdamW\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import wandb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e2f8cfd6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33maamjad\u001b[0m (\u001b[33mtab-llm-finetuning\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.3"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/ubuntu/AsteraTransformers2/experiments/ayesha/wandb/run-20240303_094537-2ocq82zq</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/tab-llm-finetuning/gpt2-sentiment-analysis/runs/2ocq82zq' target=\"_blank\">ayesha2</a></strong> to <a href='https://wandb.ai/tab-llm-finetuning/gpt2-sentiment-analysis' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/tab-llm-finetuning/gpt2-sentiment-analysis' target=\"_blank\">https://wandb.ai/tab-llm-finetuning/gpt2-sentiment-analysis</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/tab-llm-finetuning/gpt2-sentiment-analysis/runs/2ocq82zq' target=\"_blank\">https://wandb.ai/tab-llm-finetuning/gpt2-sentiment-analysis/runs/2ocq82zq</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<button onClick=\"this.nextSibling.style.display='block';this.style.display='none';\">Display W&B run</button><iframe src='https://wandb.ai/tab-llm-finetuning/gpt2-sentiment-analysis/runs/2ocq82zq?jupyter=true' style='border:none;width:100%;height:420px;display:none;'></iframe>"
      ],
      "text/plain": [
       "<wandb.sdk.wandb_run.Run at 0x7f074adbf7a0>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wandb.init(project=\"gpt2-sentiment-analysis\", name='ayesha2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2dd552f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv('data/train.csv')\n",
    "test_df = pd.read_csv('data/test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "540694fd-ead6-4590-8be0-a419e64d4aea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['review', 'sentiment'], dtype='object')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "016ea09d-8e11-4431-8688-a7ed5c5bda80",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MoviewReviewData(torch.utils.data.Dataset):\n",
    "    def __init__(self, encodings, labels):\n",
    "        self.encodings = encodings\n",
    "        self.labels = labels\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
    "        item['labels'] = torch.tensor(self.labels[idx])\n",
    "        return item\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fe3ac9f8-506c-4266-beef-0d065630c3f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 'gpt2'\n",
    "tokenizer = GPT2Tokenizer.from_pretrained(model_name)\n",
    "tokenizer.pad_token = tokenizer.eos_token\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "afeb6a70-9d6a-4175-832c-1ab6316de5a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now you can tokenize the data with padding\n",
    "train_encodings = tokenizer(train_df['review'].tolist(), truncation=True, padding=True, max_length=512)\n",
    "test_encodings = tokenizer(test_df['review'].tolist(), truncation=True, padding=True, max_length=512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1db88cfb-7454-4ddf-8318-24192e2153c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert labels to numeric\n",
    "train_labels = train_df['sentiment'].map({'positive': 1, 'negative': 0}).tolist()\n",
    "test_labels = test_df['sentiment'].map({'positive': 1, 'negative': 0}).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4b79b93d-6246-4c1c-9db6-0184f29e35b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the dataset\n",
    "train_dataset = MoviewReviewData(train_encodings, train_labels)\n",
    "test_dataset = MoviewReviewData(test_encodings, test_labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "97ce0ef7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of GPT2ForSequenceClassification were not initialized from the model checkpoint at gpt2 and are newly initialized: ['score.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "config = GPT2Config.from_pretrained(model_name, pad_token_id=tokenizer.eos_token_id, num_labels=2)\n",
    "model = GPT2ForSequenceClassification.from_pretrained(model_name, config=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0553c1a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.config.pad_token_id = tokenizer.eos_token_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fb883d8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading training arguments...\n",
      "Start training...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='10151' max='15000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [10151/15000 9:28:56 < 4:31:49, 0.30 it/s, Epoch 2.71/4]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>1.254600</td>\n",
       "      <td>0.922140</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>1.034700</td>\n",
       "      <td>0.730896</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>0.831000</td>\n",
       "      <td>0.581736</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.506700</td>\n",
       "      <td>0.320715</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>0.460700</td>\n",
       "      <td>0.373226</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.430000</td>\n",
       "      <td>0.429388</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>350</td>\n",
       "      <td>0.448100</td>\n",
       "      <td>0.262077</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.426100</td>\n",
       "      <td>0.310390</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>450</td>\n",
       "      <td>0.345200</td>\n",
       "      <td>0.305080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.348200</td>\n",
       "      <td>0.322495</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>550</td>\n",
       "      <td>0.412900</td>\n",
       "      <td>0.291711</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.332000</td>\n",
       "      <td>0.266169</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>650</td>\n",
       "      <td>0.374900</td>\n",
       "      <td>0.255901</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>700</td>\n",
       "      <td>0.378800</td>\n",
       "      <td>0.311534</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>750</td>\n",
       "      <td>0.346500</td>\n",
       "      <td>0.353655</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>800</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.395253</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>850</td>\n",
       "      <td>0.401100</td>\n",
       "      <td>0.376716</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>900</td>\n",
       "      <td>0.297800</td>\n",
       "      <td>0.315983</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>950</td>\n",
       "      <td>0.348100</td>\n",
       "      <td>0.268429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.283000</td>\n",
       "      <td>0.323237</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1050</td>\n",
       "      <td>0.364400</td>\n",
       "      <td>0.227082</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1100</td>\n",
       "      <td>0.256400</td>\n",
       "      <td>0.260343</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1150</td>\n",
       "      <td>0.237100</td>\n",
       "      <td>0.331257</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1200</td>\n",
       "      <td>0.372500</td>\n",
       "      <td>0.275972</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1250</td>\n",
       "      <td>0.346500</td>\n",
       "      <td>0.299418</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1300</td>\n",
       "      <td>0.309000</td>\n",
       "      <td>0.280571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1350</td>\n",
       "      <td>0.317100</td>\n",
       "      <td>0.284442</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1400</td>\n",
       "      <td>0.373300</td>\n",
       "      <td>0.213439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1450</td>\n",
       "      <td>0.299500</td>\n",
       "      <td>0.236089</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>0.255800</td>\n",
       "      <td>0.355055</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1550</td>\n",
       "      <td>0.354100</td>\n",
       "      <td>0.327497</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1600</td>\n",
       "      <td>0.323400</td>\n",
       "      <td>0.242062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1650</td>\n",
       "      <td>0.276800</td>\n",
       "      <td>0.270789</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1700</td>\n",
       "      <td>0.242900</td>\n",
       "      <td>0.281375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1750</td>\n",
       "      <td>0.291500</td>\n",
       "      <td>0.278023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1800</td>\n",
       "      <td>0.343100</td>\n",
       "      <td>0.244349</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1850</td>\n",
       "      <td>0.272600</td>\n",
       "      <td>0.272202</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1900</td>\n",
       "      <td>0.294800</td>\n",
       "      <td>0.275946</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1950</td>\n",
       "      <td>0.232300</td>\n",
       "      <td>0.288479</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.334900</td>\n",
       "      <td>0.239228</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2050</td>\n",
       "      <td>0.316900</td>\n",
       "      <td>0.237400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2100</td>\n",
       "      <td>0.266900</td>\n",
       "      <td>0.288038</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2150</td>\n",
       "      <td>0.295000</td>\n",
       "      <td>0.291834</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2200</td>\n",
       "      <td>0.295300</td>\n",
       "      <td>0.262063</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2250</td>\n",
       "      <td>0.306700</td>\n",
       "      <td>0.242788</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2300</td>\n",
       "      <td>0.313400</td>\n",
       "      <td>0.279344</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2350</td>\n",
       "      <td>0.309800</td>\n",
       "      <td>0.271415</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2400</td>\n",
       "      <td>0.293700</td>\n",
       "      <td>0.241588</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2450</td>\n",
       "      <td>0.260400</td>\n",
       "      <td>0.243213</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2500</td>\n",
       "      <td>0.307900</td>\n",
       "      <td>0.254353</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2550</td>\n",
       "      <td>0.338600</td>\n",
       "      <td>0.260904</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2600</td>\n",
       "      <td>0.326200</td>\n",
       "      <td>0.205431</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2650</td>\n",
       "      <td>0.243800</td>\n",
       "      <td>0.287597</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2700</td>\n",
       "      <td>0.263000</td>\n",
       "      <td>0.336240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2750</td>\n",
       "      <td>0.245000</td>\n",
       "      <td>0.267501</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2800</td>\n",
       "      <td>0.287800</td>\n",
       "      <td>0.249369</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2850</td>\n",
       "      <td>0.237300</td>\n",
       "      <td>0.235562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2900</td>\n",
       "      <td>0.306100</td>\n",
       "      <td>0.225840</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2950</td>\n",
       "      <td>0.248500</td>\n",
       "      <td>0.284044</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>0.244700</td>\n",
       "      <td>0.260507</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3050</td>\n",
       "      <td>0.218400</td>\n",
       "      <td>0.283681</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3100</td>\n",
       "      <td>0.257600</td>\n",
       "      <td>0.288008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3150</td>\n",
       "      <td>0.338200</td>\n",
       "      <td>0.238973</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3200</td>\n",
       "      <td>0.340700</td>\n",
       "      <td>0.226950</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3250</td>\n",
       "      <td>0.296600</td>\n",
       "      <td>0.222807</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3300</td>\n",
       "      <td>0.193200</td>\n",
       "      <td>0.260131</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3350</td>\n",
       "      <td>0.332200</td>\n",
       "      <td>0.242016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3400</td>\n",
       "      <td>0.237700</td>\n",
       "      <td>0.243450</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3450</td>\n",
       "      <td>0.229700</td>\n",
       "      <td>0.339992</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3500</td>\n",
       "      <td>0.267700</td>\n",
       "      <td>0.256009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3550</td>\n",
       "      <td>0.249700</td>\n",
       "      <td>0.240222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3600</td>\n",
       "      <td>0.269500</td>\n",
       "      <td>0.220051</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3650</td>\n",
       "      <td>0.274700</td>\n",
       "      <td>0.259339</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3700</td>\n",
       "      <td>0.295200</td>\n",
       "      <td>0.227009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3750</td>\n",
       "      <td>0.229700</td>\n",
       "      <td>0.295225</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3800</td>\n",
       "      <td>0.181900</td>\n",
       "      <td>0.253855</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3850</td>\n",
       "      <td>0.178400</td>\n",
       "      <td>0.267215</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3900</td>\n",
       "      <td>0.253200</td>\n",
       "      <td>0.278905</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3950</td>\n",
       "      <td>0.210100</td>\n",
       "      <td>0.271212</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4000</td>\n",
       "      <td>0.228400</td>\n",
       "      <td>0.263905</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4050</td>\n",
       "      <td>0.207900</td>\n",
       "      <td>0.352875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4100</td>\n",
       "      <td>0.187100</td>\n",
       "      <td>0.284021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4150</td>\n",
       "      <td>0.234600</td>\n",
       "      <td>0.350522</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4200</td>\n",
       "      <td>0.236500</td>\n",
       "      <td>0.248678</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4250</td>\n",
       "      <td>0.231700</td>\n",
       "      <td>0.251874</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4300</td>\n",
       "      <td>0.165800</td>\n",
       "      <td>0.280696</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4350</td>\n",
       "      <td>0.217600</td>\n",
       "      <td>0.301317</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4400</td>\n",
       "      <td>0.137400</td>\n",
       "      <td>0.315978</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4450</td>\n",
       "      <td>0.223600</td>\n",
       "      <td>0.352383</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4500</td>\n",
       "      <td>0.200500</td>\n",
       "      <td>0.295983</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4550</td>\n",
       "      <td>0.191100</td>\n",
       "      <td>0.346390</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4600</td>\n",
       "      <td>0.227300</td>\n",
       "      <td>0.334998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4650</td>\n",
       "      <td>0.171400</td>\n",
       "      <td>0.331852</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4700</td>\n",
       "      <td>0.179400</td>\n",
       "      <td>0.323095</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4750</td>\n",
       "      <td>0.252700</td>\n",
       "      <td>0.348511</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4800</td>\n",
       "      <td>0.228600</td>\n",
       "      <td>0.287056</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4850</td>\n",
       "      <td>0.199500</td>\n",
       "      <td>0.325456</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4900</td>\n",
       "      <td>0.271000</td>\n",
       "      <td>0.264635</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4950</td>\n",
       "      <td>0.253600</td>\n",
       "      <td>0.264554</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5000</td>\n",
       "      <td>0.233500</td>\n",
       "      <td>0.252661</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5050</td>\n",
       "      <td>0.131100</td>\n",
       "      <td>0.272149</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5100</td>\n",
       "      <td>0.287000</td>\n",
       "      <td>0.248975</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5150</td>\n",
       "      <td>0.263700</td>\n",
       "      <td>0.210294</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5200</td>\n",
       "      <td>0.199700</td>\n",
       "      <td>0.277111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5250</td>\n",
       "      <td>0.205800</td>\n",
       "      <td>0.271886</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5300</td>\n",
       "      <td>0.228600</td>\n",
       "      <td>0.383845</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5350</td>\n",
       "      <td>0.186000</td>\n",
       "      <td>0.309341</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5400</td>\n",
       "      <td>0.188400</td>\n",
       "      <td>0.278844</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5450</td>\n",
       "      <td>0.213400</td>\n",
       "      <td>0.266585</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5500</td>\n",
       "      <td>0.219700</td>\n",
       "      <td>0.267056</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5550</td>\n",
       "      <td>0.203000</td>\n",
       "      <td>0.293953</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5600</td>\n",
       "      <td>0.189600</td>\n",
       "      <td>0.301708</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5650</td>\n",
       "      <td>0.193600</td>\n",
       "      <td>0.287512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5700</td>\n",
       "      <td>0.169700</td>\n",
       "      <td>0.304788</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5750</td>\n",
       "      <td>0.287200</td>\n",
       "      <td>0.285400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5800</td>\n",
       "      <td>0.193600</td>\n",
       "      <td>0.260081</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5850</td>\n",
       "      <td>0.235800</td>\n",
       "      <td>0.264068</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5900</td>\n",
       "      <td>0.269700</td>\n",
       "      <td>0.252614</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5950</td>\n",
       "      <td>0.221600</td>\n",
       "      <td>0.255240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6000</td>\n",
       "      <td>0.157600</td>\n",
       "      <td>0.296766</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6050</td>\n",
       "      <td>0.164900</td>\n",
       "      <td>0.298489</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6100</td>\n",
       "      <td>0.259100</td>\n",
       "      <td>0.270630</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6150</td>\n",
       "      <td>0.173400</td>\n",
       "      <td>0.260254</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6200</td>\n",
       "      <td>0.199300</td>\n",
       "      <td>0.280883</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6250</td>\n",
       "      <td>0.231700</td>\n",
       "      <td>0.273884</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6300</td>\n",
       "      <td>0.218500</td>\n",
       "      <td>0.256867</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6350</td>\n",
       "      <td>0.158400</td>\n",
       "      <td>0.287116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6400</td>\n",
       "      <td>0.168300</td>\n",
       "      <td>0.278768</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6450</td>\n",
       "      <td>0.177400</td>\n",
       "      <td>0.356607</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6500</td>\n",
       "      <td>0.170200</td>\n",
       "      <td>0.285776</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6550</td>\n",
       "      <td>0.186500</td>\n",
       "      <td>0.277623</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6600</td>\n",
       "      <td>0.175100</td>\n",
       "      <td>0.307437</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6650</td>\n",
       "      <td>0.235200</td>\n",
       "      <td>0.334549</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6700</td>\n",
       "      <td>0.189800</td>\n",
       "      <td>0.297617</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6750</td>\n",
       "      <td>0.152800</td>\n",
       "      <td>0.304467</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6800</td>\n",
       "      <td>0.213600</td>\n",
       "      <td>0.278056</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6850</td>\n",
       "      <td>0.215400</td>\n",
       "      <td>0.251498</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6900</td>\n",
       "      <td>0.125400</td>\n",
       "      <td>0.283491</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6950</td>\n",
       "      <td>0.117000</td>\n",
       "      <td>0.292883</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7000</td>\n",
       "      <td>0.167300</td>\n",
       "      <td>0.300277</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7050</td>\n",
       "      <td>0.196500</td>\n",
       "      <td>0.300253</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7100</td>\n",
       "      <td>0.270500</td>\n",
       "      <td>0.293973</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7150</td>\n",
       "      <td>0.196300</td>\n",
       "      <td>0.278839</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7200</td>\n",
       "      <td>0.277700</td>\n",
       "      <td>0.232812</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7250</td>\n",
       "      <td>0.153300</td>\n",
       "      <td>0.249897</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7300</td>\n",
       "      <td>0.169600</td>\n",
       "      <td>0.252079</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7350</td>\n",
       "      <td>0.213200</td>\n",
       "      <td>0.263155</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7400</td>\n",
       "      <td>0.193800</td>\n",
       "      <td>0.249130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7450</td>\n",
       "      <td>0.126000</td>\n",
       "      <td>0.257733</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7500</td>\n",
       "      <td>0.218100</td>\n",
       "      <td>0.269179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7550</td>\n",
       "      <td>0.164000</td>\n",
       "      <td>0.269727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7600</td>\n",
       "      <td>0.134100</td>\n",
       "      <td>0.372890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7650</td>\n",
       "      <td>0.074600</td>\n",
       "      <td>0.330066</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7700</td>\n",
       "      <td>0.211400</td>\n",
       "      <td>0.289521</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7750</td>\n",
       "      <td>0.161400</td>\n",
       "      <td>0.283931</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7800</td>\n",
       "      <td>0.113600</td>\n",
       "      <td>0.299414</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7850</td>\n",
       "      <td>0.160100</td>\n",
       "      <td>0.297739</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7900</td>\n",
       "      <td>0.074100</td>\n",
       "      <td>0.339415</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7950</td>\n",
       "      <td>0.140700</td>\n",
       "      <td>0.339804</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8000</td>\n",
       "      <td>0.143200</td>\n",
       "      <td>0.312110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8050</td>\n",
       "      <td>0.165500</td>\n",
       "      <td>0.287832</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8100</td>\n",
       "      <td>0.132000</td>\n",
       "      <td>0.304396</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8150</td>\n",
       "      <td>0.114200</td>\n",
       "      <td>0.399814</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8200</td>\n",
       "      <td>0.125500</td>\n",
       "      <td>0.329850</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8250</td>\n",
       "      <td>0.096100</td>\n",
       "      <td>0.342054</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8300</td>\n",
       "      <td>0.234300</td>\n",
       "      <td>0.298008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8350</td>\n",
       "      <td>0.199200</td>\n",
       "      <td>0.276883</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8400</td>\n",
       "      <td>0.091200</td>\n",
       "      <td>0.320796</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8450</td>\n",
       "      <td>0.119000</td>\n",
       "      <td>0.323326</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8500</td>\n",
       "      <td>0.039800</td>\n",
       "      <td>0.355955</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8550</td>\n",
       "      <td>0.103400</td>\n",
       "      <td>0.375321</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8600</td>\n",
       "      <td>0.090300</td>\n",
       "      <td>0.353570</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8650</td>\n",
       "      <td>0.039200</td>\n",
       "      <td>0.378279</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8700</td>\n",
       "      <td>0.147200</td>\n",
       "      <td>0.342992</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8750</td>\n",
       "      <td>0.137600</td>\n",
       "      <td>0.309675</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8800</td>\n",
       "      <td>0.139400</td>\n",
       "      <td>0.344656</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8850</td>\n",
       "      <td>0.117200</td>\n",
       "      <td>0.284962</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8900</td>\n",
       "      <td>0.120100</td>\n",
       "      <td>0.314572</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8950</td>\n",
       "      <td>0.181700</td>\n",
       "      <td>0.342884</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9000</td>\n",
       "      <td>0.069800</td>\n",
       "      <td>0.293814</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9050</td>\n",
       "      <td>0.118400</td>\n",
       "      <td>0.344088</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9100</td>\n",
       "      <td>0.077000</td>\n",
       "      <td>0.334259</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9150</td>\n",
       "      <td>0.102500</td>\n",
       "      <td>0.351732</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9200</td>\n",
       "      <td>0.106600</td>\n",
       "      <td>0.367059</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9250</td>\n",
       "      <td>0.103500</td>\n",
       "      <td>0.350497</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9300</td>\n",
       "      <td>0.094000</td>\n",
       "      <td>0.332045</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9350</td>\n",
       "      <td>0.125400</td>\n",
       "      <td>0.359674</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9400</td>\n",
       "      <td>0.205100</td>\n",
       "      <td>0.345592</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9450</td>\n",
       "      <td>0.159800</td>\n",
       "      <td>0.304112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9500</td>\n",
       "      <td>0.088100</td>\n",
       "      <td>0.332695</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9550</td>\n",
       "      <td>0.117800</td>\n",
       "      <td>0.327255</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9600</td>\n",
       "      <td>0.138600</td>\n",
       "      <td>0.331024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9650</td>\n",
       "      <td>0.112400</td>\n",
       "      <td>0.363019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9700</td>\n",
       "      <td>0.178300</td>\n",
       "      <td>0.305809</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9750</td>\n",
       "      <td>0.112400</td>\n",
       "      <td>0.319078</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9800</td>\n",
       "      <td>0.129300</td>\n",
       "      <td>0.319122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9850</td>\n",
       "      <td>0.108100</td>\n",
       "      <td>0.318697</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9900</td>\n",
       "      <td>0.110700</td>\n",
       "      <td>0.323658</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9950</td>\n",
       "      <td>0.100700</td>\n",
       "      <td>0.310268</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10000</td>\n",
       "      <td>0.179300</td>\n",
       "      <td>0.313238</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10050</td>\n",
       "      <td>0.170300</td>\n",
       "      <td>0.337608</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10100</td>\n",
       "      <td>0.171200</td>\n",
       "      <td>0.330478</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>\n",
       "    <div>\n",
       "      \n",
       "      <progress value='9' max='2500' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [   9/2500 00:00 < 02:38, 15.73 it/s]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(\"Loading training arguments...\")\n",
    "training_args = TrainingArguments(\n",
    "    output_dir='data/result',  # output directory for model and checkpoints\n",
    "    num_train_epochs=4,           # total number of training epochs\n",
    "    evaluation_strategy=\"steps\",\n",
    "    per_device_train_batch_size=8,   # batch size per device during training\n",
    "    per_device_eval_batch_size=8,    # batch size for evaluation\n",
    "    warmup_steps=500,                # number of warmup steps for learning rate scheduler\n",
    "    weight_decay=0.01,               # strength of weight decay\n",
    "    logging_dir='data/logs',            # directory for storing logs\n",
    "    logging_steps=50,\n",
    "    save_steps=1000,\n",
    "    save_total_limit=2,\n",
    "    report_to=\"wandb\",                # Disables wandb logging\n",
    ")\n",
    "\n",
    "# Initialize the Trainer\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=test_dataset\n",
    ")\n",
    "\n",
    "# Fine-tune the model\n",
    "print(\"Start training...\")\n",
    "trainer.train()\n",
    "\n",
    "print(\"Saving finetuned gpt2...\")\n",
    "model.save_pretrained('data/result/fine_tuned_gpt2_model')\n",
    "tokenizer.save_pretrained('data/result/fine_tuned_gpt2_model')\n",
    "\n",
    "print(\"Start testing...\")\n",
    "# eval mode on model\n",
    "trainer.evaluate()\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53aedb00-fcfc-4b52-8051-0f71c5187a1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = train_df['review']\n",
    "y_train = train_df['sentiment']\n",
    "X_test = test_df['review']\n",
    "y_test = test_df['sentiment']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea3000cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = GPT2ForSequenceClassification.from_pretrained('data/result/fine_tuned_gpt2_model')\n",
    "tokenizer = GPT2Tokenizer.from_pretrained('data/result/fine_tuned_gpt2_model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1e3636e-b455-4510-a947-c35aa19eced4",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_numeric = y_train.map({'positive': 1, 'negative': 0}).astype(int)\n",
    "y_test_numeric = y_test.map({'positive': 1, 'negative': 0}).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21af4680",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "#test_encodings = tokenizer(test_data['review'].tolist(), truncation=True, padding=True, max_length=512, return_tensors=\"pt\")\n",
    "\n",
    "# Convert labels to a tensor\n",
    "labels = torch.tensor(y_test_numeric)\n",
    "\n",
    "# Create a DataLoader for the test set (optional, for batch processing)\n",
    "test_dataset = MoviewReviewData(test_encodings, labels)\n",
    "test_loader = DataLoader(test_dataset, batch_size=16)\n",
    "\n",
    "def evaluate(model, test_loader):\n",
    "    model.eval()  # Set the model to evaluation mode\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model.to(device)\n",
    "\n",
    "    correct_predictions = 0\n",
    "    total_predictions = 0\n",
    "\n",
    "    for batch in test_loader:\n",
    "        input_ids = batch['input_ids'].to(device)\n",
    "        attention_mask = batch['attention_mask'].to(device)\n",
    "        labels = batch['labels'].to(device)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            outputs = model(input_ids, attention_mask=attention_mask)\n",
    "            predictions = torch.argmax(outputs.logits, dim=1)\n",
    "            correct_predictions += (predictions == labels).sum().item()\n",
    "            total_predictions += labels.size(0)\n",
    "\n",
    "    accuracy = (correct_predictions / total_predictions) * 100\n",
    "    return accuracy\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy = evaluate(model, test_loader)\n",
    "print(f\"Model accuracy on the test set: {accuracy:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62f0dac0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42fe93f4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2e2b103",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "182fd9ff",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3fc8cad",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0b0d064",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53998b2c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73562579",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40da8291",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18419c94",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
