{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31d5970c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install wandb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b5c55709",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from transformers import GPT2Tokenizer, GPT2Config, GPT2ForSequenceClassification, AdamW\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "import pandas as pd\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "import re\n",
    "import wandb\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5d26c8bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import TextDataset, DataCollatorForLanguageModeling\n",
    "from transformers import GPT2Tokenizer, GPT2LMHeadModel\n",
    "from transformers import Trainer, TrainingArguments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "01dd1057",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33maamjad\u001b[0m (\u001b[33mtab-llm-finetuning\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.3 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.2"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/ubuntu/Downloads/AsteraTransformers/experiment-ayesha/wandb/run-20240224_173319-iexqu8ap</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/tab-llm-finetuning/testanalytics/runs/iexqu8ap' target=\"_blank\">sentiment-analysis-1</a></strong> to <a href='https://wandb.ai/tab-llm-finetuning/testanalytics' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/tab-llm-finetuning/testanalytics' target=\"_blank\">https://wandb.ai/tab-llm-finetuning/testanalytics</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/tab-llm-finetuning/testanalytics/runs/iexqu8ap' target=\"_blank\">https://wandb.ai/tab-llm-finetuning/testanalytics/runs/iexqu8ap</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<button onClick=\"this.nextSibling.style.display='block';this.style.display='none';\">Display W&B run</button><iframe src='https://wandb.ai/tab-llm-finetuning/testanalytics/runs/iexqu8ap?jupyter=true' style='border:none;width:100%;height:420px;display:none;'></iframe>"
      ],
      "text/plain": [
       "<wandb.sdk.wandb_run.Run at 0x7fe8f70648e0>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wandb.init(project='testanalytics', name='sentiment-analysis-1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "20d1332e",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv('data/train.csv')\n",
    "test_df = pd.read_csv('data/test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "208ec0fd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SAPS AT SEA &lt;br /&gt;&lt;br /&gt;Aspect ratio: 1.37:1&lt;b...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>If you want mindless action, hot chicks and a ...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>\"The Woman in Black\" is easily one of the cree...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>I can barely find the words to describe how mu...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>What's in here ?! Let me tell you. It's the pr...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29995</th>\n",
       "      <td>I was really looking forward to this show give...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29996</th>\n",
       "      <td>I searched for this movie for years, apparentl...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29997</th>\n",
       "      <td>This is a story of the Winchester Rifle Model ...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29998</th>\n",
       "      <td>this film is in the MANDINGO &amp; DRUM type&lt;br /&gt;...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29999</th>\n",
       "      <td>Ha ha. - oh no - what to say about this film? ...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>30000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  review sentiment\n",
       "0      SAPS AT SEA <br /><br />Aspect ratio: 1.37:1<b...  negative\n",
       "1      If you want mindless action, hot chicks and a ...  positive\n",
       "2      \"The Woman in Black\" is easily one of the cree...  positive\n",
       "3      I can barely find the words to describe how mu...  negative\n",
       "4      What's in here ?! Let me tell you. It's the pr...  negative\n",
       "...                                                  ...       ...\n",
       "29995  I was really looking forward to this show give...  negative\n",
       "29996  I searched for this movie for years, apparentl...  positive\n",
       "29997  This is a story of the Winchester Rifle Model ...  positive\n",
       "29998  this film is in the MANDINGO & DRUM type<br />...  negative\n",
       "29999  Ha ha. - oh no - what to say about this film? ...  negative\n",
       "\n",
       "[30000 rows x 2 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec64c0c4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8dc3680",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 'gpt2'\n",
    "\n",
    "tokenizer = GPT2Tokenizer.from_pretrained('gpt2')\n",
    "config = GPT2Config.from_pretrained('gpt2', num_labels=2)\n",
    "model = GPT2ForSequenceClassification.from_pretrained('gpt2', config=config)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "00ad19f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "id2label = {0: \"negative\", 1: \"positive\"}\n",
    "label2id = {\"negative\": 0, \"positive\": 1}\n",
    "train_df['sentiment'] = train_df['sentiment'].map(label2id)\n",
    "test_df['sentiment'] = test_df['sentiment'].map(label2id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "999e33f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cleaning(s):\n",
    "    s = str(s)\n",
    "    s = re.sub(r'<br />',' ',s)\n",
    "    s = re.sub('\\W,\\s',' ',s)\n",
    "    s = re.sub(r'[^A-Za-z0-9.,\\'\"()-]',' ',s)\n",
    "    s = re.sub(\"\\d+\", \"\", s)\n",
    "    s = re.sub('\\s+',' ',s)\n",
    "    s = re.sub('[!@#$_]', '', s)\n",
    "    s = s.replace(\"co\",\"\")\n",
    "    s = s.replace(\"https\",\"\")\n",
    "    s = s.replace(\"[\\w*\",\" \")\n",
    "    return s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "54199492",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df['review'] = train_df['review'].apply(cleaning)\n",
    "test_df['review'] = test_df['review'].apply(cleaning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b47d6cf8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9bfcab77",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SAPS AT SEA Aspect ratio . Sound format Mono (...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>If you want mindless action, hot chicks and a ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>\"The Woman in Black\" is easily one of the cree...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>I can barely find the words to describe how mu...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>What's in here Let me tell you. It's the prese...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29995</th>\n",
       "      <td>I was really looking forward to this show give...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29996</th>\n",
       "      <td>I searched for this movie for years, apparentl...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29997</th>\n",
       "      <td>This is a story of the Winchester Rifle Model ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29998</th>\n",
       "      <td>this film is in the MANDINGO DRUM type they we...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29999</th>\n",
       "      <td>Ha ha. - oh no - what to say about this film Y...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>30000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  review  sentiment\n",
       "0      SAPS AT SEA Aspect ratio . Sound format Mono (...          0\n",
       "1      If you want mindless action, hot chicks and a ...          1\n",
       "2      \"The Woman in Black\" is easily one of the cree...          1\n",
       "3      I can barely find the words to describe how mu...          0\n",
       "4      What's in here Let me tell you. It's the prese...          0\n",
       "...                                                  ...        ...\n",
       "29995  I was really looking forward to this show give...          0\n",
       "29996  I searched for this movie for years, apparentl...          1\n",
       "29997  This is a story of the Winchester Rifle Model ...          1\n",
       "29998  this film is in the MANDINGO DRUM type they we...          0\n",
       "29999  Ha ha. - oh no - what to say about this film Y...          0\n",
       "\n",
       "[30000 rows x 2 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4dbd70c3",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Steven Rea plays a forensic scientist thrust o...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>As the first of the TV specials offered on the...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>There may something poetically right in seeing...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>all i can say about this film is to read the b...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>I thought it was a pretty good movie and shoul...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19995</th>\n",
       "      <td>Well-done ghost story that will give you the c...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19996</th>\n",
       "      <td>I'm at a loss for words. This movie is beyond ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19997</th>\n",
       "      <td>First off, I had my doubts just looking at the...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19998</th>\n",
       "      <td>In an early scene, Luca (David Pasquesi) and J...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19999</th>\n",
       "      <td>I have no idea why people are so crazy about t...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>20000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  review  sentiment\n",
       "0      Steven Rea plays a forensic scientist thrust o...          1\n",
       "1      As the first of the TV specials offered on the...          1\n",
       "2      There may something poetically right in seeing...          0\n",
       "3      all i can say about this film is to read the b...          0\n",
       "4      I thought it was a pretty good movie and shoul...          1\n",
       "...                                                  ...        ...\n",
       "19995  Well-done ghost story that will give you the c...          1\n",
       "19996  I'm at a loss for words. This movie is beyond ...          0\n",
       "19997  First off, I had my doubts just looking at the...          0\n",
       "19998  In an early scene, Luca (David Pasquesi) and J...          1\n",
       "19999  I have no idea why people are so crazy about t...          0\n",
       "\n",
       "[20000 rows x 2 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9c664563",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_reviews, train_sentiment = train_df['review'].tolist(), train_df['sentiment'].tolist()\n",
    "test_reviews, test_sentiment = test_df['review'].tolist(), test_df['sentiment'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cde94238",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_reviews, val_review, train_sentiment, val_sentiment = train_test_split(train_reviews, train_sentiment, test_size=0.1, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6d46d35a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of GPT2ForSequenceClassification were not initialized from the model checkpoint at gpt2 and are newly initialized: ['score.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model_name = 'gpt2'\n",
    "\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_name)\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "tokenizer.add_special_tokens({'pad_token': '[PAD]'})\n",
    "# print memory footprint\n",
    "print(\"Memory footprint of gpt2_model: \", gpt2_model.num_parameters() * 4 / 1024 / 1024, \"MB\")\n",
    "\n",
    "#tokenizer = GPT2Tokenizer.from_pretrained(model_name)\n",
    "#tokenizer.add_special_tokens({'pad_token': '[PAD]'})\n",
    "#model = GPT2ForSequenceClassification.from_pretrained(model_name, num_labels=2)  # Assuming 2 classes for sentiment analysis\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ef975ed9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenize the data\n",
    "train_enc = tokenizer(train_reviews, truncation=True, padding=True, max_length=128, return_tensors='pt')\n",
    "val_enc = tokenizer(val_review, truncation=True, padding=True, max_length=128, return_tensors='pt')\n",
    "test_enc = tokenizer(test_reviews, truncation=True, padding=True, max_length=128, return_tensors='pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bb41f5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_collator(samples):\n",
    "    input_ids = tokenized_datasets[\"train\"]['input_ids']\n",
    "    attention_mask = tokenized_datasets[\"train\"]['attention_mask']\n",
    "    #labels = tokenized_datasets[\"train\"]['input_ids']\n",
    "\n",
    "    return {\n",
    "        'input_ids': input_ids,\n",
    "        'attention_mask': attention_mask,\n",
    "        #'labels': labels\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8f2b4ba9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "class SentimentDataset(Dataset):\n",
    "    def __init__(self, encodings, labels):\n",
    "        self.encodings = encodings\n",
    "        self.labels = labels\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
    "        item['sentiment'] = torch.tensor(self.labels[idx])\n",
    "        return item\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "038fde92",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = SentimentDataset(train_enc, train_sentiment)\n",
    "val_dataset = SentimentDataset(val_enc, val_sentiment)\n",
    "test_dataset = SentimentDataset(test_enc, test_sentiment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfafcc3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#train_dataset = TextDataset(train_enc, torch.tensor(train_sentiment), block_size=128)\n",
    "#val_dataset = TextDataset(val_enc, torch.tensor(val_sentiment), block_size=128)\n",
    "#test_dataset = TextDataset(test_enc, torch.tensor(test_sentiment), block_size=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "51c0e024",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_collator = DataCollatorForLanguageModeling(tokenizer=tokenizer, mlm=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "639b3b4f",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "CUDA error: device-side assert triggered\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[22], line 14\u001b[0m\n\u001b[1;32m      1\u001b[0m output_dir \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdata/result\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m      2\u001b[0m training_args \u001b[38;5;241m=\u001b[39m TrainingArguments(\n\u001b[1;32m      3\u001b[0m     output_dir\u001b[38;5;241m=\u001b[39moutput_dir,\n\u001b[1;32m      4\u001b[0m     overwrite_output_dir\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     10\u001b[0m     report_to\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mwandb\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m     11\u001b[0m )\n\u001b[0;32m---> 14\u001b[0m trainer \u001b[38;5;241m=\u001b[39m \u001b[43mTrainer\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     15\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     16\u001b[0m \u001b[43m    \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtraining_args\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     17\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdata_collator\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdata_collator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     18\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrain_dataset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain_dataset\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     19\u001b[0m \u001b[43m    \u001b[49m\u001b[43meval_dataset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mval_dataset\u001b[49m\n\u001b[1;32m     20\u001b[0m \u001b[43m)\u001b[49m\n\u001b[1;32m     23\u001b[0m trainer\u001b[38;5;241m.\u001b[39mtrain()\n",
      "File \u001b[0;32m~/Downloads/enter/envs/mllm/lib/python3.10/site-packages/transformers/trainer.py:337\u001b[0m, in \u001b[0;36mTrainer.__init__\u001b[0;34m(self, model, args, data_collator, train_dataset, eval_dataset, tokenizer, model_init, compute_metrics, callbacks, optimizers, preprocess_logits_for_metrics)\u001b[0m\n\u001b[1;32m    335\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs \u001b[38;5;241m=\u001b[39m args\n\u001b[1;32m    336\u001b[0m \u001b[38;5;66;03m# Seed must be set before instantiating the model when using model\u001b[39;00m\n\u001b[0;32m--> 337\u001b[0m enable_full_determinism(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mseed) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mfull_determinism \u001b[38;5;28;01melse\u001b[39;00m \u001b[43mset_seed\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mseed\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    338\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhp_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    339\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdeepspeed \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/Downloads/enter/envs/mllm/lib/python3.10/site-packages/transformers/trainer_utils.py:95\u001b[0m, in \u001b[0;36mset_seed\u001b[0;34m(seed)\u001b[0m\n\u001b[1;32m     93\u001b[0m np\u001b[38;5;241m.\u001b[39mrandom\u001b[38;5;241m.\u001b[39mseed(seed)\n\u001b[1;32m     94\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_torch_available():\n\u001b[0;32m---> 95\u001b[0m     \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmanual_seed\u001b[49m\u001b[43m(\u001b[49m\u001b[43mseed\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     96\u001b[0m     torch\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39mmanual_seed_all(seed)\n\u001b[1;32m     97\u001b[0m     \u001b[38;5;66;03m# ^^ safe to call this function even if cuda is not available\u001b[39;00m\n",
      "File \u001b[0;32m~/Downloads/enter/envs/mllm/lib/python3.10/site-packages/torch/random.py:40\u001b[0m, in \u001b[0;36mmanual_seed\u001b[0;34m(seed)\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcuda\u001b[39;00m\n\u001b[1;32m     39\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39m_is_in_bad_fork():\n\u001b[0;32m---> 40\u001b[0m     \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcuda\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmanual_seed_all\u001b[49m\u001b[43m(\u001b[49m\u001b[43mseed\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     42\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmps\u001b[39;00m\n\u001b[1;32m     43\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mmps\u001b[38;5;241m.\u001b[39m_is_in_bad_fork():\n",
      "File \u001b[0;32m~/Downloads/enter/envs/mllm/lib/python3.10/site-packages/torch/cuda/random.py:113\u001b[0m, in \u001b[0;36mmanual_seed_all\u001b[0;34m(seed)\u001b[0m\n\u001b[1;32m    110\u001b[0m         default_generator \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39mdefault_generators[i]\n\u001b[1;32m    111\u001b[0m         default_generator\u001b[38;5;241m.\u001b[39mmanual_seed(seed)\n\u001b[0;32m--> 113\u001b[0m \u001b[43m_lazy_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcb\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mseed_all\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Downloads/enter/envs/mllm/lib/python3.10/site-packages/torch/cuda/__init__.py:183\u001b[0m, in \u001b[0;36m_lazy_call\u001b[0;34m(callable, **kwargs)\u001b[0m\n\u001b[1;32m    181\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_lazy_call\u001b[39m(\u001b[38;5;28mcallable\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    182\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m is_initialized():\n\u001b[0;32m--> 183\u001b[0m         \u001b[38;5;28;43mcallable\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    184\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    185\u001b[0m         \u001b[38;5;66;03m# TODO(torch_deploy): this accesses linecache, which attempts to read the\u001b[39;00m\n\u001b[1;32m    186\u001b[0m         \u001b[38;5;66;03m# file system to get traceback info. Patch linecache or do something\u001b[39;00m\n\u001b[1;32m    187\u001b[0m         \u001b[38;5;66;03m# else here if this ends up being important.\u001b[39;00m\n\u001b[1;32m    188\u001b[0m         \u001b[38;5;28;01mglobal\u001b[39;00m _lazy_seed_tracker\n",
      "File \u001b[0;32m~/Downloads/enter/envs/mllm/lib/python3.10/site-packages/torch/cuda/random.py:111\u001b[0m, in \u001b[0;36mmanual_seed_all.<locals>.cb\u001b[0;34m()\u001b[0m\n\u001b[1;32m    109\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(device_count()):\n\u001b[1;32m    110\u001b[0m     default_generator \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39mdefault_generators[i]\n\u001b[0;32m--> 111\u001b[0m     \u001b[43mdefault_generator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmanual_seed\u001b[49m\u001b[43m(\u001b[49m\u001b[43mseed\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: CUDA error: device-side assert triggered\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n"
     ]
    }
   ],
   "source": [
    "output_dir = 'data/result'\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=output_dir,\n",
    "    overwrite_output_dir=True,\n",
    "    per_device_train_batch_size=8,\n",
    "    num_train_epochs=4,\n",
    "    save_steps=500,  # Adjust as needed\n",
    "    save_total_limit=2,\n",
    "    fp16=False,\n",
    "    report_to='wandb'\n",
    ")\n",
    "\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    data_collator=data_collator,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=val_dataset\n",
    ")\n",
    "\n",
    "\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd0620fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = trainer.evaluate(test_dataset)\n",
    "accuracy = results['eval_accuracy']\n",
    "wandb.log({\"Test Accuracy\": accuracy})\n",
    "wandb.finish()  # Finish W&B run\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95fd306c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Accuracy on test set: {accuracy}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfa2e2ee",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7705e346",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7945ea3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37831b1e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e8d39ca",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73c74f7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "train(\n",
    "    train_file_path=train_file_path,\n",
    "    model_name=model_name,\n",
    "    output_dir=output_dir,\n",
    "    overwrite_output_dir=overwrite_output_dir,\n",
    "    per_device_train_batch_size=per_device_train_batch_size,\n",
    "    num_train_epochs=num_train_epochs,\n",
    "    save_steps=save_steps\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cf5ab3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import PreTrainedTokenizerFast, GPT2LMHeadModel, GPT2TokenizerFast, GPT2Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a6d3e8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.read_csv(\"data/test.csv\")\n",
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f648185",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd19ce6b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43f2bec8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_text(sequence, max_length):\n",
    "    model_path = 'data/result'\n",
    "    model = load_model(model_path)\n",
    "    tokenizer = load_tokenizer(model_path)\n",
    "    ids = tokenizer.encode(f'{sequence}', return_tensors='pt')\n",
    "    final_outputs = model.generate(\n",
    "        ids,\n",
    "        do_sample=True,\n",
    "        max_length=max_length,\n",
    "        pad_token_id=model.config.eos_token_id,\n",
    "        top_k=50,\n",
    "        top_p=0.95,\n",
    "    )\n",
    "    print(tokenizer.decode(final_outputs[0], skip_special_tokens=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92b6d551",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab421469",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70801964",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "048ac60f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bf6ef49",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
