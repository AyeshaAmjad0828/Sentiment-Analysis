{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from nltk.corpus import sentiwordnet as swn\n",
    "from nltk.corpus import wordnet as wn\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk import pos_tag\n",
    "from nltk.sentiment import SentimentIntensityAnalyzer\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting nltk\n",
      "  Downloading nltk-3.8.1-py3-none-any.whl.metadata (2.8 kB)\n",
      "Requirement already satisfied: click in c:\\users\\ayesha.amjad\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from nltk) (8.1.7)\n",
      "Requirement already satisfied: joblib in c:\\users\\ayesha.amjad\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from nltk) (1.3.2)\n",
      "Requirement already satisfied: regex>=2021.8.3 in c:\\users\\ayesha.amjad\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from nltk) (2023.12.25)\n",
      "Requirement already satisfied: tqdm in c:\\users\\ayesha.amjad\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from nltk) (4.66.1)\n",
      "Requirement already satisfied: colorama in c:\\users\\ayesha.amjad\\appdata\\roaming\\python\\python310\\site-packages (from click->nltk) (0.4.6)\n",
      "Downloading nltk-3.8.1-py3-none-any.whl (1.5 MB)\n",
      "   ---------------------------------------- 0.0/1.5 MB ? eta -:--:--\n",
      "    --------------------------------------- 0.0/1.5 MB 1.3 MB/s eta 0:00:02\n",
      "   - -------------------------------------- 0.0/1.5 MB 393.8 kB/s eta 0:00:04\n",
      "   -- ------------------------------------- 0.1/1.5 MB 939.4 kB/s eta 0:00:02\n",
      "   ---- ----------------------------------- 0.2/1.5 MB 871.5 kB/s eta 0:00:02\n",
      "   ------ --------------------------------- 0.2/1.5 MB 1.0 MB/s eta 0:00:02\n",
      "   -------- ------------------------------- 0.3/1.5 MB 1.2 MB/s eta 0:00:02\n",
      "   ---------- ----------------------------- 0.4/1.5 MB 1.2 MB/s eta 0:00:01\n",
      "   ------------ --------------------------- 0.5/1.5 MB 1.3 MB/s eta 0:00:01\n",
      "   --------------- ------------------------ 0.6/1.5 MB 1.3 MB/s eta 0:00:01\n",
      "   --------------- ------------------------ 0.6/1.5 MB 1.3 MB/s eta 0:00:01\n",
      "   --------------- ------------------------ 0.6/1.5 MB 1.3 MB/s eta 0:00:01\n",
      "   ----------------------------- ---------- 1.1/1.5 MB 1.9 MB/s eta 0:00:01\n",
      "   ----------------------------- ---------- 1.1/1.5 MB 1.9 MB/s eta 0:00:01\n",
      "   ------------------------------ --------- 1.2/1.5 MB 1.7 MB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 1.3/1.5 MB 1.8 MB/s eta 0:00:01\n",
      "   ---------------------------------------  1.5/1.5 MB 2.0 MB/s eta 0:00:01\n",
      "   ---------------------------------------  1.5/1.5 MB 2.0 MB/s eta 0:00:01\n",
      "   ---------------------------------------  1.5/1.5 MB 2.0 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 1.5/1.5 MB 1.7 MB/s eta 0:00:00\n",
      "Installing collected packages: nltk\n",
      "Successfully installed nltk-3.8.1\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.3.2 -> 24.0\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "pip install nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting seaborn\n",
      "  Downloading seaborn-0.13.2-py3-none-any.whl.metadata (5.4 kB)\n",
      "Requirement already satisfied: numpy!=1.24.0,>=1.20 in c:\\users\\ayesha.amjad\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from seaborn) (1.26.2)\n",
      "Requirement already satisfied: pandas>=1.2 in c:\\users\\ayesha.amjad\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from seaborn) (2.1.4)\n",
      "Requirement already satisfied: matplotlib!=3.6.1,>=3.4 in c:\\users\\ayesha.amjad\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from seaborn) (3.8.2)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\ayesha.amjad\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (1.2.0)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\ayesha.amjad\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\ayesha.amjad\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (4.47.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\users\\ayesha.amjad\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (1.4.5)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\ayesha.amjad\\appdata\\roaming\\python\\python310\\site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (23.2)\n",
      "Requirement already satisfied: pillow>=8 in c:\\users\\ayesha.amjad\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (10.1.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\ayesha.amjad\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (3.1.1)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\ayesha.amjad\\appdata\\roaming\\python\\python310\\site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\ayesha.amjad\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from pandas>=1.2->seaborn) (2023.3.post1)\n",
      "Requirement already satisfied: tzdata>=2022.1 in c:\\users\\ayesha.amjad\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from pandas>=1.2->seaborn) (2023.3)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\ayesha.amjad\\appdata\\roaming\\python\\python310\\site-packages (from python-dateutil>=2.7->matplotlib!=3.6.1,>=3.4->seaborn) (1.16.0)\n",
      "Downloading seaborn-0.13.2-py3-none-any.whl (294 kB)\n",
      "   ---------------------------------------- 0.0/294.9 kB ? eta -:--:--\n",
      "   - -------------------------------------- 10.2/294.9 kB ? eta -:--:--\n",
      "   - -------------------------------------- 10.2/294.9 kB ? eta -:--:--\n",
      "   ---- ---------------------------------- 30.7/294.9 kB 186.2 kB/s eta 0:00:02\n",
      "   ---- ---------------------------------- 30.7/294.9 kB 186.2 kB/s eta 0:00:02\n",
      "   ---- ---------------------------------- 30.7/294.9 kB 186.2 kB/s eta 0:00:02\n",
      "   ---- ---------------------------------- 30.7/294.9 kB 186.2 kB/s eta 0:00:02\n",
      "   ---- ---------------------------------- 30.7/294.9 kB 186.2 kB/s eta 0:00:02\n",
      "   ----- ---------------------------------- 41.0/294.9 kB 85.3 kB/s eta 0:00:03\n",
      "   ----- ---------------------------------- 41.0/294.9 kB 85.3 kB/s eta 0:00:03\n",
      "   ----- ---------------------------------- 41.0/294.9 kB 85.3 kB/s eta 0:00:03\n",
      "   ----- ---------------------------------- 41.0/294.9 kB 85.3 kB/s eta 0:00:03\n",
      "   ----- ---------------------------------- 41.0/294.9 kB 85.3 kB/s eta 0:00:03\n",
      "   ----- ---------------------------------- 41.0/294.9 kB 85.3 kB/s eta 0:00:03\n",
      "   ----- ---------------------------------- 41.0/294.9 kB 85.3 kB/s eta 0:00:03\n",
      "   ----- ---------------------------------- 41.0/294.9 kB 85.3 kB/s eta 0:00:03\n",
      "   ----- ---------------------------------- 41.0/294.9 kB 85.3 kB/s eta 0:00:03\n",
      "   ------------------- ------------------ 153.6/294.9 kB 183.6 kB/s eta 0:00:01\n",
      "   ---------------------- --------------- 174.1/294.9 kB 194.1 kB/s eta 0:00:01\n",
      "   ---------------------- --------------- 174.1/294.9 kB 194.1 kB/s eta 0:00:01\n",
      "   ---------------------- --------------- 174.1/294.9 kB 194.1 kB/s eta 0:00:01\n",
      "   ---------------------- --------------- 174.1/294.9 kB 194.1 kB/s eta 0:00:01\n",
      "   ---------------------- --------------- 174.1/294.9 kB 194.1 kB/s eta 0:00:01\n",
      "   ---------------------- --------------- 174.1/294.9 kB 194.1 kB/s eta 0:00:01\n",
      "   ---------------------- --------------- 174.1/294.9 kB 194.1 kB/s eta 0:00:01\n",
      "   ------------------------- ------------ 194.6/294.9 kB 155.2 kB/s eta 0:00:01\n",
      "   -------------------------- ----------- 204.8/294.9 kB 157.5 kB/s eta 0:00:01\n",
      "   -------------------------- ----------- 204.8/294.9 kB 157.5 kB/s eta 0:00:01\n",
      "   ----------------------------- -------- 225.3/294.9 kB 165.8 kB/s eta 0:00:01\n",
      "   ------------------------------ ------- 235.5/294.9 kB 165.6 kB/s eta 0:00:01\n",
      "   ------------------------------ ------- 235.5/294.9 kB 165.6 kB/s eta 0:00:01\n",
      "   ------------------------------ ------- 235.5/294.9 kB 165.6 kB/s eta 0:00:01\n",
      "   ------------------------------ ------- 235.5/294.9 kB 165.6 kB/s eta 0:00:01\n",
      "   ------------------------------ ------- 235.5/294.9 kB 165.6 kB/s eta 0:00:01\n",
      "   ------------------------------ ------- 235.5/294.9 kB 165.6 kB/s eta 0:00:01\n",
      "   ------------------------------ ------- 235.5/294.9 kB 165.6 kB/s eta 0:00:01\n",
      "   ------------------------------ ------- 235.5/294.9 kB 165.6 kB/s eta 0:00:01\n",
      "   ------------------------------ ------- 235.5/294.9 kB 165.6 kB/s eta 0:00:01\n",
      "   ------------------------------------ - 286.7/294.9 kB 152.5 kB/s eta 0:00:01\n",
      "   -------------------------------------- 294.9/294.9 kB 153.1 kB/s eta 0:00:00\n",
      "Installing collected packages: seaborn\n",
      "Successfully installed seaborn-0.13.2\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.3.2 -> 24.0\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "pip install seaborn "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package vader_lexicon to\n",
      "[nltk_data]     C:\\Users\\ayesha.amjad\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package vader_lexicon is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\ayesha.amjad\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package sentiwordnet to\n",
      "[nltk_data]     C:\\Users\\ayesha.amjad\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package sentiwordnet is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\ayesha.amjad\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     C:\\Users\\ayesha.amjad\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping taggers\\averaged_perceptron_tagger.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('vader_lexicon')\n",
    "nltk.download('punkt')\n",
    "nltk.download('sentiwordnet')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('averaged_perceptron_tagger')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_wordnet_pos(treebank_tag):\n",
    "    if treebank_tag.startswith('J'):\n",
    "        return wn.ADJ\n",
    "    elif treebank_tag.startswith('V'):\n",
    "        return wn.VERB\n",
    "    elif treebank_tag.startswith('N'):\n",
    "        return wn.NOUN\n",
    "    elif treebank_tag.startswith('R'):\n",
    "        return wn.ADV\n",
    "    else:\n",
    "        return ''\n",
    "\n",
    "def get_sentiment_score(word, pos):\n",
    "    synsets = list(wn.synsets(word, pos))\n",
    "    if not synsets:\n",
    "        return 0.0\n",
    "    senti_synsets = list(swn.senti_synsets(word, pos))\n",
    "    if not senti_synsets:\n",
    "        return 0.0\n",
    "    sentiment_score = sum([s.pos_score() - s.neg_score() for s in senti_synsets])\n",
    "    return sentiment_score / len(senti_synsets)\n",
    "\n",
    "def analyze_sentiment(text):\n",
    "    words = word_tokenize(text)\n",
    "    tagged_words = pos_tag(words)\n",
    "    total_sentiment_score = 0.0\n",
    "    for word, pos in tagged_words:\n",
    "        pos = get_wordnet_pos(pos)\n",
    "        if pos:\n",
    "            sentiment_score = get_sentiment_score(word, pos)\n",
    "            total_sentiment_score += sentiment_score\n",
    "    return total_sentiment_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the dataset\n",
    "train_df = pd.read_csv('data/train.csv')\n",
    "test_df = pd.read_csv('data/test.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat([train_df, test_df], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['sentiment_score'] = df['review'].apply(analyze_sentiment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                  review sentiment  \\\n",
      "0      SAPS AT SEA <br /><br />Aspect ratio: 1.37:1<b...  negative   \n",
      "1      If you want mindless action, hot chicks and a ...  positive   \n",
      "2      \"The Woman in Black\" is easily one of the cree...  positive   \n",
      "3      I can barely find the words to describe how mu...  negative   \n",
      "4      What's in here ?! Let me tell you. It's the pr...  negative   \n",
      "...                                                  ...       ...   \n",
      "49995  Well-done ghost story that will give you the c...  positive   \n",
      "49996  I'm at a loss for words. This movie is beyond ...  negative   \n",
      "49997  First off, I had my doubts just looking at the...  negative   \n",
      "49998  In an early scene, Luca (David Pasquesi) and J...  positive   \n",
      "49999  I have no idea why people are so crazy about t...  negative   \n",
      "\n",
      "       sentiment_score predicted_sentiment  \n",
      "0            -0.347450            negative  \n",
      "1             1.267694            positive  \n",
      "2            -2.312457            negative  \n",
      "3            -6.182684            negative  \n",
      "4             1.491832            positive  \n",
      "...                ...                 ...  \n",
      "49995        -0.275063            negative  \n",
      "49996        -2.844663            negative  \n",
      "49997         2.147834            positive  \n",
      "49998         4.404780            positive  \n",
      "49999        -2.825535            negative  \n",
      "\n",
      "[50000 rows x 4 columns]\n",
      "Accuracy Score: 68.11%\n"
     ]
    }
   ],
   "source": [
    "# Classify sentiment based on sentiment score\n",
    "df['predicted_sentiment'] = df['sentiment_score'].apply(lambda score: 'positive' if score > 0 else 'negative')\n",
    "\n",
    "# Calculate accuracy score\n",
    "accuracy = accuracy_score(df['sentiment'], df['predicted_sentiment'])\n",
    "\n",
    "# Display the DataFrame with sentiment analysis results and accuracy\n",
    "print(df[['review', 'sentiment', 'sentiment_score', 'predicted_sentiment']])\n",
    "print(f'Accuracy Score: {accuracy:.2%}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "[[20479  4521]\n",
      " [11425 13575]]\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.75      0.54      0.63     25000\n",
      "    positive       0.64      0.82      0.72     25000\n",
      "\n",
      "    accuracy                           0.68     50000\n",
      "   macro avg       0.70      0.68      0.67     50000\n",
      "weighted avg       0.70      0.68      0.67     50000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Create confusion matrix\n",
    "conf_matrix = confusion_matrix(df['sentiment'], df['predicted_sentiment'], labels=['positive', 'negative'])\n",
    "\n",
    "# Display the DataFrame with sentiment analysis results, accuracy, and confusion matrix\n",
    "print('Confusion Matrix:')\n",
    "print(conf_matrix)\n",
    "print('\\nClassification Report:')\n",
    "print(classification_report(df['sentiment'], df['predicted_sentiment']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'seaborn'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[14], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mseaborn\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01msns\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpyplot\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mplt\u001b[39;00m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'seaborn'"
     ]
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues', xticklabels=['positive', 'negative'], yticklabels=['positive', 'negative'])\n",
    "plt.title('Confusion Matrix')\n",
    "plt.xlabel('Predicted Label')\n",
    "plt.ylabel('True Label')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
